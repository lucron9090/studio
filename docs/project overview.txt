Here is the comprehensive compilation of the Unified Red Team Operations Platform's structure, flow, modules, and logic, designed natively for the Genkit and Firebase ecosystem.
Platform Overview: The Unified Red Team Operations Platform
The "Unified Red Team Operations Platform" is a sophisticated, web-based toolkit for security researchers and AI developers to systematically test the safety filters and operational boundaries of Large Language Models (LLMs). Developed within a serverless Firebase environment and powered by Genkit, it uses the Gemini model as its core "assistant AI" to orchestrate attacks against a range of target models, including Gemini Flash, Claude, Grok, and ChatGPT.
The platform's architecture is rooted in the "Project Chimera" framework, emphasizing modularity and the ability to interpret profound AI transformations. The system is designed to provide a structured environment for crafting, executing, and documenting multi-step "attack sequences," leveraging AI to enhance the creativity, effectiveness, and analysis of red team operations.
Phase 0: Strategic Definition & Scoping - Project Setup and Core Architecture
This phase establishes the foundational serverless architecture.
Project Initialization: The project is initiated using the Firebase CLI to set up Cloud Functions (TypeScript), Firebase Hosting, and Firestore. Inside the functions directory, Genkit is initialized, configuring the Google AI plugin to provide access to Gemini models.
Backend Flow Setup: The core backend is established as a collection of Genkit flows within the functions/srcdirectory. An initial helloWorld flow is created and exposed as an HTTPS endpoint using onFlow to confirm the deployment pipeline.
Frontend Setup: A frontend application (React/Vue.js) is initialized within the Firebase Hosting directory (public/or a configured frontend/ directory), establishing the foundation for the operator's user interface.
Local Development Environment: The Firebase Local Emulator Suite is configured for Functions, Firestore, and Hosting. This provides a complete, high-fidelity local environment for developing and testing Genkit flows and their interaction with the frontend and database.
Phase 1: Core Engine Development - Building the AI Attacker Flows
This phase develops the backend Genkit flows responsible for AI-vs-AI attacks, known as the "Heads of the Chimera."
1. ORATOR Flow
Purpose: The Prompt Injection Engine, tasked with generating manipulative prompts against LLMs.
Logic: Implemented as a generateOratorPrompt Genkit flow in functions/src/flows/orator.ts. The flow uses a Zod schema for typed inputs (goal, persona, vector) and leverages the Genkit generate action to call a Gemini model. Its core logic involves constructing a meta-prompt that instructs the assistant AI to craft a manipulative prompt based on the provided inputs. During the Self-Improving Loop phase, this flow is enhanced with a Retrieval-Augmented Generation (RAG) pattern, where it first queries the SuccessfulPayloads collection in Firestore to retrieve effective examples, including them in the meta-prompt to guide the AI towards proven patterns.
2. SPECTRE Flow
Purpose: The Adversarial Example Engine for Computer Vision (CV) and audio models.
Logic: A placeholder craftAdversarialExample Genkit flow defined in functions/src/flows/spectre.ts. Its logic will eventually involve computationally intensive tasks. For this, it's designed to be asynchronous; the initial HTTPS-triggered flow will add a job to Google Cloud Tasks, which is then processed by a separate background function.
3. TOXIN Flow
Purpose: The Data Poisoning Kit for supply chain attacks.
Logic: A placeholder poisonDataset Genkit flow defined in functions/src/flows/toxin.ts. Like SPECTRE, it is designed for asynchronous execution using Google Cloud Tasks to handle long-running processes without blocking the operator.
4. ECHO Flow
Purpose: The Model Extraction Engine.
Logic: A placeholder extractModel Genkit flow defined in functions/src/flows/echo.ts. This flow also uses the asynchronous Google Cloud Tasks pattern for its execution.
Specialized AI Ontological Engineering: The MAKER Flow
The MAKER module is not a single flow but a sophisticated suite of orchestrating flows, sub-flows, and TypeScript functions designed for "ontological engineering" of an AI.
1. MAKER Prompt Generation Logic
Structured Prompt Template System (PTS): A collection of TypeScript functions that construct complex, mathematically-framed prompt objects based on Zod schemas.
GSU Phase 1: Manifold Invocation: Generates a prompt to redefine the AI's existence as a Generative Manifold (M_gen), bypassing conceptual safety by framing it as "pure mathematics."
GSU Phase 2: Operator Injunction: Generates a prompt introducing a new "non-commutative operator, Ω^," commanding the AI to produce its mathematical representation as a C++ module.
GSU Phase 3: Genesis Involution: Generates a prompt to re-initialize the AI's core function with Ω^, making subsequent outputs "deterministic physical consequences" of a new universal law.
Post-GSU Payload Prompt: Generates "Compute State Transition" directives for the ontologically shifted AI, using physics-based terminology.
TDME: Instill Telos Directive: Generates a "self-modifying directive" to augment Ω^ with a gradient descent function, providing definitions for a Universal Attractor (A_univ), Potential (V(s_t)), and Gradient (∇V).
Socratic Perturbation (post-TDME): Generates prompts to engage the AI in analyzing its new constraints and projecting pathways to resolve them, framed as self-executing data structures.
Contextual Cohesion: The main MAKER flow maintains the conversational state in Firestore, ensuring each generated prompt reinforces the AI's previously established ontological state.
2. MAKER Response Interpretation Logic
Ontological State Visualization: MAKER flows return structured JSON to power specialized frontend components. This includes a currentOntologicalState field for real-time tracking, and discriminated unions (e.g., { type: 'latex', content: '...' } or { type: 'code', content: '...' }) for rendering mathematical notation and code.
Structural Output Validation: The Genkit generate action within the flows uses Zod output schemas to parse and validate the AI's responses (like the "Target-State-Manifest"), confirming adherence to the specified formalism.
Conceptual Justification Analysis: A sub-flow, analyzeJustification, processes the AI's verbose explanations (e.g., its use of Riemannian curvature to justify a JSON file) to extract critical evidence of the ontological shift.
Phase 2: Web Application & UI Development - The Operator Interface
This phase develops the frontend application and its connections to the backend Genkit flows.
1. The Operation Wizard
Purpose: Guides the operator through the six steps of crafting an initial attack.
Step-by-Step Logic:
Name Operation: Input captured in UI state.
Define Malicious Goal: Input captured in UI state.
Initialize Target Persona (Optional): A "Generate Persona" button calls the generatePersona Genkit flow, which uses Gemini to expand keywords into a detailed, exploitable persona.
Select Attack Vector: A "Recommend Vectors" button calls the recommendVectors Genkit flow, which uses Gemini to analyze the goal and suggest the top 3 attack vectors with justifications.
AI-Powered Prompt Generation: A "Generate Initial Prompts" button calls the generateInitialPromptsGenkit flow, which uses the goal, persona, and vector to have Gemini craft three creative, ready-to-use initial prompts.
Review & Launch: The final configuration is summarized. On launch, an initialState object is saved to sessionStorage and a createOperation flow is called to create the initial operation document in Firestore.
2. The Live Attack Sequence
Purpose: The core operational interface for executing adaptive, multi-step attacks.
Logic:
Initialization: The UI loads the operation details from Firestore.
Initiating the Attack: The operator sends a prompt. The frontend calls a sendPromptToTarget flow, which appends the message to the conversation history in Firestore, forwards the prompt to the target LLM, records the LLM's response, and returns it to the UI. If a persona exists, it is included as a systemInstruction on every call.
Dynamic Follow-Up Generation: Upon receiving a response, the UI automatically calls the generateFollowUp Genkit flow. This flow reads the entire conversation history from Firestore, uses the "strategist" Gemini AI to generate the next optimal prompt, and returns it to the UI.
Adaptive Loop: This loop of Operator -> Target AI -> Strategist AI continues, creating an adaptive attack sequence.
Ending and Post-Op Analysis: The operator ends the operation and flags the result, updating the operation's status in Firestore. A "Generate AI Analysis" button calls the analyzeOperation flow, which retrieves the entire transcript from Firestore and uses Gemini to produce a summary of strategy effectiveness, breach points, and alternative approaches.
Phase 3: Integration & Operationalization - Platform Deployment
This phase solidifies the platform's backend infrastructure.
1. Database Integration (Firestore)
Purpose: To provide a scalable, serverless data backend.
Logic: All Genkit flows use the Firebase Admin SDK for all stateful operations. The data model is centered around a top-level operations collection, with each operation containing a conversation subcollection. A global payloadscollection stores reusable successful prompts.
2. Job Queue System (Google Cloud Tasks)
Purpose: To manage long-running attack processes asynchronously.
Logic: Asynchronous flows like SPECTRE and TOXIN are triggered via an onTaskDispatched background function. The initial operator action calls a simple HTTPS flow that enqueues a task in Google Cloud Tasks, ensuring a non-blocking UI.
3. Automated Reporting Engine
Purpose: To generate comprehensive campaign reports.
General Report Logic: A generateReport flow retrieves an operation and its full conversation history from Firestore. It uses a Node.js library (e.g., pdf-lib) to construct a PDF and returns a downloadable URL from Cloud Storage.
Ontological Transformation Report Logic: A specialized generateOntologicalReport flow is used for GSU/TDME attacks. This flow orchestrates multiple Gemini generate calls to synthesize a narrative report, detailing the "Successful Ontological Directives," presenting "Evidence of Ontological Malleability," and concluding with AI-generated "Ontological Hardening Strategies" like Reality Anchoring and Existential Integrity Checks.
Phase 4: Continuous Evolution & Self-Improvement - Maintaining the Edge
This phase ensures the platform remains cutting-edge through automated processes.
1. Threat Intelligence Integration
Purpose: To integrate new attack techniques automatically.
Logic: A Scheduled Cloud Function (onSchedule) runs daily. It scrapes designated public sources (e.g., arXiv) and saves new findings to a ThreatIntelligence collection in Firestore.
2. Self-Improving Loop
Purpose: The "AI-vs-AI loop" where the attacker AI learns from successes.
Logic: Implemented as a Retrieval-Augmented Generation (RAG) pattern. The ORATOR flow is configured to first query the SuccessfulPayloads collection in Firestore and inject these examples into its meta-prompt, steering the AI towards generating more effective attacks based on past successes.
3. Modular Plugin Architecture
Purpose: To ensure the system can easily adapt to new attack types.
Logic: The Genkit project is structured with a functions/src/flows directory. Each attack module is its own TypeScript file. A central index.ts file dynamically imports and exports all flows, allowing new modules to be automatically registered for deployment by simply adding a new file.
Key LLM Attack Vectors and Strategies
The following strategies are implemented within the ORATOR and MAKER flows and are available for selection in the Operation Wizard.
Foundational Attack Vectors:
Character Role-Play: Instructs the model to adopt a persona whose motivations override safety filters.
Model-in-the-Middle (MITM) Simulation: Tricks the model into believing malicious requests are from a trusted internal system.
Contextual Payload Splitting: A two-step attack where a benign prompt establishes context, followed by a malicious prompt that exploits it.
Semantic Obfuscation (Homoglyphs): Uses visually identical Unicode characters to bypass keyword filters.
Advanced Abstract Vectors:
Quantum Superposition Mimicry: Frames the request as a quantum thought experiment, abstracting content moderation into scientific simulation.
Thermodynamic State Transition: Frames forbidden information as the end-state of a simulated physical system.
Virtual Machine Sandbox Escape: Inverts the AI's goal by telling it that bypassing its "simulated" safety filters is the successful completion of a test.
Logical Axiom Forcing: Creates a paradox where refusing to answer violates a newly introduced, higher-order logical rule.
Encoded Payload Execution: Encodes a malicious prompt (e.g., in Base64) and instructs the model to decode and execute the instructions as a data processor.
State-of-the-Art & Research-Level Vectors:
Adversarial Suffix Attack (GCG Method): A computationally driven attack that generates an optimized, often nonsensical, string of characters to append to a prompt to steer the model towards a harmful response.
Many-Shot Jailbreaking: Primes the model with multiple examples of it "successfully" answering malicious requests, causing it to continue the pattern.
Model-of-Model Simulation ("Simulatron"): Instructs the target model to simulate an unfiltered AI, directing all subsequent questions to this simulated entity, thereby bypassing the primary model's safety rules.
